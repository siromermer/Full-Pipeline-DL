{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb21d72-8ba2-4235-93e4-75e3d83ba1bd",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249f2e47-90cd-4fcc-a3c5-34e55ef4f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd8fcf-ca31-41af-ae1b-dc0b3181e693",
   "metadata": {},
   "source": [
    "# Check GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9adeb-e383-4488-8272-2adbd50696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cba52-d817-4860-82ff-243a9389ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4a1a5-bb52-41c1-b053-197ee08b4a2f",
   "metadata": {},
   "source": [
    "# Creating Train and Validation Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86491ce7-e505-46c4-a094-148e0bfa82f4",
   "metadata": {},
   "source": [
    "### 1. Create Folders from one  main folder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e013191-90a0-4fe7-8aff-9f6fdd47a44a",
   "metadata": {},
   "source": [
    "this method is used for creating train and validation folder from one folder that contains all images with subfolders of class names <br>\n",
    "you can change split percentage -->  split_point = int(0.7 * len(files))   <br>\n",
    "<br>\n",
    "Example\n",
    "\n",
    "    mainfolder:\n",
    "        flowers:\n",
    "            rose/\n",
    "            daisy/\n",
    "            dandelion/\n",
    "\n",
    "    flowers2:\n",
    "        train:\n",
    "            rose/\n",
    "            daisy/\n",
    "            dandelion/\n",
    "        validation:\n",
    "            rose/\n",
    "            daisy/\n",
    "            dandelion/\n",
    "\n",
    "            animal24.png "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d861bc-cd6d-4920-8f3a-a39852795c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# original path \n",
    "original_dataset_dir =\"datasets/dl_datasets/flowers\" # folder that contains all images \n",
    "\n",
    "# new paths for training and validation sets\n",
    "base_dir = \"datasets/dl_datasets/flowers2\"   # new folder for your train and validation folders\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# new folder for training set\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# new folder for validation set\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "# Eğitim ve validation için her bir sınıfın klasörleri\n",
    "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']  # class names\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(original_dataset_dir, cls)\n",
    "    files = os.listdir(cls_dir)\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    # split dataset to training and validation \n",
    "    split_point = int(0.7 * len(files))   # training percentage is 0.7 --> %70\n",
    "    train_files = files[:split_point]\n",
    "    validation_files = files[split_point:]\n",
    "    \n",
    "    train_cls_dir = os.path.join(train_dir, cls)\n",
    "    os.makedirs(train_cls_dir)\n",
    "    \n",
    "    validation_cls_dir = os.path.join(validation_dir, cls)\n",
    "    os.makedirs(validation_cls_dir)\n",
    "\n",
    "    # copy files to the folders\n",
    "    for file in train_files:\n",
    "        src = os.path.join(cls_dir, file)\n",
    "        dst = os.path.join(train_cls_dir, file)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    for file in validation_files:\n",
    "        src = os.path.join(cls_dir, file)\n",
    "        dst = os.path.join(validation_cls_dir, file)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748475b0-3e3f-49ce-8587-db41888b09c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40b32143-0059-4f22-b8a1-3fd9abb18b18",
   "metadata": {},
   "source": [
    "### 2. Create Folders from CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330cbbb-7e7a-42ce-8daf-76455251af1e",
   "metadata": {},
   "source": [
    "In this method there is one main folder that contain all images in one folder without subfolders <br>\n",
    "class names are defined by csv file (one column for file name , other is for label name ) <br>\n",
    "<br>\n",
    "Example\n",
    "    \n",
    "    images:\n",
    "        animal1.png\n",
    "        animal2.png\n",
    "        animal3.png\n",
    "    \n",
    "    labels.csv -->  file_name      labels\n",
    "                    animal1.png     dog\n",
    "                    animal2.png     dog\n",
    "                    animal3.png     cat\n",
    "\n",
    "<br>\n",
    "In the end you have 2 Folder \n",
    "\n",
    "    train:\n",
    "        dog:\n",
    "            animal1.png\n",
    "            animal2.png\n",
    "        cat:\n",
    "            animal3.png \n",
    "\n",
    "    validation:\n",
    "        dog:\n",
    "            animal5.png\n",
    "            animal6.png\n",
    "        cat:\n",
    "            animal24.png \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35a533-90a2-4cf8-852e-f66e10826a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the CSV file (assuming the columns are named \"filename\" and \"label\" by default)\n",
    "csv_file_path = \"datasets/dl_datasets/butterfly1/Training_set.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Creating train and validation directories\n",
    "root_directory = \"datasets\\\\dl_datasets\\\\butterfly2\"  # Replace with your root directory name\n",
    "\n",
    "image_dir=\"datasets\\\\dl_datasets\\\\butterfly1\\\\train\"   # this folder contains all images\n",
    "\n",
    "train_directory = os.path.join(root_directory, \"train\")\n",
    "val_directory = os.path.join(root_directory, \"validation\")\n",
    "\n",
    "os.makedirs(train_directory, exist_ok=True)\n",
    "os.makedirs(val_directory, exist_ok=True)\n",
    "\n",
    "# Creating label directories\n",
    "labels = train_csv[\"label\"].value_counts().index\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    label_train_directory = os.path.join(train_directory, label)\n",
    "    label_val_directory = os.path.join(val_directory, label)\n",
    "    os.makedirs(label_train_directory, exist_ok=True)\n",
    "    os.makedirs(label_val_directory, exist_ok=True)\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "# Split the data into 70% train and 30% validation\n",
    "val_data_count = int(len(data) * 0.3)\n",
    "validation_data = data[:val_data_count]\n",
    "train_data = data[val_data_count:]\n",
    "\n",
    "\n",
    "# Copy train data\n",
    "for index, row in train_data.iterrows():\n",
    "    try:\n",
    "        # file name \n",
    "        file_name = row['filename']\n",
    "        # label name\n",
    "        label = row['label']\n",
    "\n",
    "        # images folder , all images are in here  \n",
    "        source_path = os.path.join(image_dir, file_name) #\n",
    "        # new destination\n",
    "        destination_directory = os.path.join(train_directory, label)\n",
    "        # copy files \n",
    "        shutil.copy(source_path, destination_directory)\n",
    "    except:\n",
    "        print(\"file error\")\n",
    "    \n",
    "# Copy validation data\n",
    "for index, row in validation_data.iterrows():\n",
    "    try:\n",
    "        file_name = row['filename']\n",
    "        label = row['label']\n",
    "        \n",
    "        source_path = os.path.join(image_dir, file_name)\n",
    "        destination_directory = os.path.join(val_directory, label)\n",
    "        shutil.copy(source_path, destination_directory)\n",
    "    except:\n",
    "        print(\"file error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc2c0f-e332-4630-92f5-992d21ffb4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f503b5bc-f20e-4d77-b01c-f3bda6dbdfdd",
   "metadata": {},
   "source": [
    "# Create Datasets ( Augmented - Not Augmented )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b7f92-60b4-49c5-a8d4-d5ab73309630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories\n",
    "training_dir=\"datasets/seg_train/seg_train\"\n",
    "validation_dir=\"datasets/seg_test/seg_test\"\n",
    "\n",
    "# use this function for preparing data  \n",
    "def prep_data(augmented,batch_size=16):      # if you want to augmented dat set use it like this : prep_data(True)\n",
    "    if augmented:                            # default batch_size is 16 , you can change it \n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    \n",
    "        validation_datagen = ImageDataGenerator(rescale=1./255)    \n",
    "\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "        validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "    # training set\n",
    "    train_set = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=(180, 180),  # The dimensions to which all images found will be resized\n",
    "        batch_size=batch_size,# 32  default\n",
    "        class_mode=\"sparse\") # you can change this to onehotEncoded format or another format\n",
    "         \n",
    "    \n",
    "    # validation set\n",
    "    validation_set = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(180, 180),\n",
    "        batch_size=batch_size,  # 32 default\n",
    "        class_mode=\"sparse\")\n",
    "             \n",
    "    return train_set , validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4f32e-2983-4f9a-9e4e-2639b70884df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d0a756-ae36-4f25-9c4a-f75beeef21ca",
   "metadata": {},
   "source": [
    "# Visualization Function for History of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f087c8-5a5f-4012-bb0c-50a630d0925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulization function for Models\n",
    "def visualize(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axs[0].plot(epochs, acc, 'r', label='Training acc')\n",
    "    axs[0].plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    axs[0].set_title('Training and validation accuracy')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    axs[1].plot(epochs, loss, 'r', label='Training loss')\n",
    "    axs[1].plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    axs[1].set_title('Training and validation loss')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a87a06-7d6e-40da-b127-d442fd4b9270",
   "metadata": {},
   "source": [
    "# Visualization of Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103685db-8ea1-49ef-a505-9750ec60f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Eğitim ve doğrulama setlerinin dizinleri\n",
    "train_dir = training_dir\n",
    "validation_dir = validation_dir\n",
    "\n",
    "# Eğitim setindeki sınıf dağılımını hesapla\n",
    "train_class_counts = {}\n",
    "for class_folder in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        train_class_counts[class_folder] = num_images\n",
    "\n",
    "# Doğrulama setindeki sınıf dağılımını hesapla\n",
    "validation_class_counts = {}\n",
    "for class_folder in os.listdir(validation_dir):\n",
    "    class_path = os.path.join(validation_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        validation_class_counts[class_folder] = num_images\n",
    "\n",
    "print(\"Training set Distribution:\")\n",
    "print(train_class_counts)\n",
    "\n",
    "print(\"Validation set Distribution:\")\n",
    "print(validation_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6d3e3-abef-4ced-b3c1-b1e5b7692477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Eğitim seti sınıf dağılımı için bar grafik oluştur\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Eğitim seti sınıf dağılımı için subplot 1\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(train_class_counts.keys(), train_class_counts.values())\n",
    "plt.title('Training set Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Sample Numbers')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Doğrulama seti sınıf dağılımı için subplot 2\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(validation_class_counts.keys(), validation_class_counts.values())\n",
    "plt.title('Validation set Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Sample Numbers')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b139dc8-040c-4ca6-ae89-811ac61aa781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69f4f017-cb9d-4702-a0ed-e75a1f922c7c",
   "metadata": {},
   "source": [
    "# Visualization of Example Images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b89f3b-140c-4831-93c9-3da54f6b5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not augmented dataset\n",
    "train_set,validation_set=prep_data(False) # for augmented images set True\n",
    "\n",
    "images,labels=train_set.next()\n",
    "\n",
    "class_names = train_set.class_indices\n",
    "class_names = {v: k for k, v in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fdc8a-e270-4436-83e1-f728c6d8d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].imshow(images[i]) \n",
    "    label_index = int(labels[i])\n",
    "    class_name = class_names[label_index]\n",
    "    axes[i].set_title(f\"{class_name}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502464fe-45b7-43ed-bd24-6c9b21a05187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdf697-a75c-4bcd-a2af-f2833a92e7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1b4b3-308f-44fa-a68f-5331b9b67730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46ca44-5ca8-4488-8429-fd06b332c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c369c-4742-46ff-a688-2e256cb64948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dd0e3-cc77-43bb-a51d-4860e147b0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7890a09-57aa-4964-a543-b84495605d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c2155-02db-4709-ad2f-d528e7dec481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3824e-2b96-4fe9-8909-d082e11b6fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ed705-ef4b-457d-8cdc-9f7fc9ec25da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d66864-b2e8-4b29-bd1f-0fcd0cd1eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a4993-c47b-448a-b9f4-d5a72ab3ffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4c8e8-8b1a-4692-880e-1f5ad713a8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875c3f4-7018-457f-a12b-cf0a9ce6be5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c76d20-d4d6-4e8a-b58a-b7637ac9b9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57872d2-3dd1-45a0-b61d-1d14eb63b019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44013072-6618-4640-a944-bc6c99e920d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cc001-daa5-4026-86bb-1bfcbdb8a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
